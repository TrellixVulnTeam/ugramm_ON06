{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1a4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fe4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mmh3\n",
    "import re\n",
    "\n",
    "MAX_LEN_CHARS = 256*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f71159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d8af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-04-23 21:03:53 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-04-23 21:03:53 __init__:22] `pynini` is not installed ! \n",
      "    Please run the `nemo_text_processing/setup.sh` scriptprior to usage of this toolkit.\n",
      "[NeMo W 2022-04-23 21:03:53 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:03:54 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.7.2/punctuation_en_distilbert/613c4ee780c6fc158f49d3566cbd6636/punctuation_en_distilbert.nemo.\n",
      "[NeMo I 2022-04-23 21:03:54 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.7.2/punctuation_en_distilbert/613c4ee780c6fc158f49d3566cbd6636/punctuation_en_distilbert.nemo\n",
      "[NeMo I 2022-04-23 21:03:54 common:704] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-04-23 21:03:56 tokenizer_utils:125] Getting HuggingFace AutoTokenizer with pretrained_model_name: distilbert-base-uncased, vocab_file: /tmp/tmplzpcj62l/tokenizer.vocab_file, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-23 21:04:01 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-04-23 21:04:01 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-04-23 21:04:01 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-04-23 21:04:01 modelPT:1243] World size can only be set by PyTorch Lightning Trainer.\n",
      "[NeMo W 2022-04-23 21:04:01 punctuation_capitalization_model:681] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-04-23 21:04:01 punctuation_capitalization_model:703] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n",
      "[NeMo W 2022-04-23 21:04:01 modelPT:215] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertEncoder: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:04:05 save_restore_connector:157] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.7.2/punctuation_en_distilbert/613c4ee780c6fc158f49d3566cbd6636/punctuation_en_distilbert.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "\n",
    "model_distil = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name=\"punctuation_en_distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86437f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582094"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.read_csv(\"data/eng_sentences.tsv\", sep=\"\\t\", names=[\"id\", \"lang\", \"text\"])\n",
    "df_t = df_t[df_t[\"text\"].str.len() < MAX_LEN_CHARS]\n",
    "\n",
    "# shuffle\n",
    "df_t[\"id\"] = df_t[\"text\"].map(lambda x: mmh3.hash64(x.encode('utf8'))[0])\n",
    "df_t[\"text\"] = df_t[\"text\"].map(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
    "df_t[\"text\"] = df_t[\"text\"].map(lambda x: re.sub(' +', ' ', x).strip())\n",
    "df_t = df_t.sort_values(\"id\")\n",
    "len(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4f4853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66939"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o = pd.read_csv(\"data/oss.tsv\", sep=\"\\t\", names=[\"text\"])\n",
    "df_o = df_o[df_o[\"text\"].str.len() < MAX_LEN_CHARS]\n",
    "\n",
    "# shuffle\n",
    "df_o[\"id\"] = df_o[\"text\"].map(lambda x: mmh3.hash64(x.encode('utf8'))[0])\n",
    "df_o[\"text\"] = df_o[\"text\"].map(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
    "df_o[\"text\"] = df_o[\"text\"].map(lambda x: re.sub(' +', ' ', x).strip())\n",
    "df_o = df_o.sort_values(\"id\")\n",
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd145ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4102516"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g = pd.read_csv(\"data/gutenberg.tsv\", sep=\"\\t\", names=[\"text\"])\n",
    "df_g = df_g[df_g[\"text\"].str.len() < MAX_LEN_CHARS]\n",
    "\n",
    "# shuffle\n",
    "df_g[\"id\"] = df_g[\"text\"].map(lambda x: mmh3.hash64(x.encode('utf8'))[0])\n",
    "df_g[\"text\"] = df_g[\"text\"].map(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
    "df_g[\"text\"] = df_g[\"text\"].map(lambda x: re.sub(' +', ' ', x).strip())\n",
    "df_g = df_g.sort_values(\"id\")\n",
    "len(df_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0a6094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 10000\n",
    "texts_t = list(df_t[\"text\"])[-test_size:]\n",
    "texts_t = [text for text in texts_t if text.isascii()]\n",
    "len(texts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0095b97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 10000\n",
    "texts_o = list(df_o[\"text\"])[-test_size:]\n",
    "texts_o = [text for text in texts_o if text.isascii()]\n",
    "len(texts_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06749d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 10000\n",
    "texts_g = list(df_g[\"text\"])[-test_size:]\n",
    "texts_g = [text for text in texts_g if text.isascii()]\n",
    "len(texts_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06fa941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice didn't see the dog.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b053a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since the JavaScript support doesn't understand ES7 constructs, features like IntelliSense might not be fully accurate.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_o[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f77aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I don\\'t fear him, anyway he comes,\" replied Will Banion. \"I don\\'t like it, but all of this was forced on me.\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d203538",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts_t + texts_o + texts_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d095105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:05:21 punctuation_capitalization_model:1068] Using batch size 4 for inference\n",
      "[NeMo I 2022-04-23 21:05:21 punctuation_capitalization_infer_dataset:91] Max length: 27\n",
      "[NeMo I 2022-04-23 21:05:21 data_preprocessing:358] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-23 21:05:21 data_preprocessing:360] Min: 23 |                  Max: 25 |                  Mean: 24.0 |                  Median: 24.0\n",
      "[NeMo I 2022-04-23 21:05:21 data_preprocessing:366] 75 percentile: 24.25\n",
      "[NeMo I 2022-04-23 21:05:21 data_preprocessing:367] 99 percentile: 24.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['OU OO OU OO OO OO OU OO OO OO OU OO OO OO OO OO',\n",
       " 'OU OO OU OO OO OO OU OO OO OO OU OO OO OO OO .O',\n",
       " 'OU OO OU OO OO OO OU OO OO OO OU OO OO OO OO OO',\n",
       " 'OU OO OU OO OO OO OU ,O OO OO OU OO OO OO OO .O']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_distil.add_punctuation_capitalization([\n",
    "    texts_o[1],\n",
    "    texts_o[1].replace(\".\", \"\"),\n",
    "    texts_o[1].replace(\",\", \"\"),\n",
    "    texts_o[1].replace(\",\", \"\").replace(\".\", \"\"),\n",
    "], return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b387bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "156fffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punctuation(s):\n",
    "    return s.replace(\",\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed0f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:05:56 punctuation_capitalization_infer_dataset:91] Max length: 64\n",
      "[NeMo I 2022-04-23 21:05:56 data_preprocessing:358] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-23 21:05:56 data_preprocessing:360] Min: 0 |                  Max: 216 |                  Mean: 21.8305 |                  Median: 14.0\n",
      "[NeMo I 2022-04-23 21:05:56 data_preprocessing:366] 75 percentile: 27.00\n",
      "[NeMo I 2022-04-23 21:05:56 data_preprocessing:367] 99 percentile: 122.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 295/295 [02:59<00:00,  1.64batch/s]\n"
     ]
    }
   ],
   "source": [
    "texts_without_punctuation = [\n",
    "    clean_punctuation(text) for text in texts\n",
    "]\n",
    "preds = model_distil.add_punctuation_capitalization(texts_without_punctuation, batch_size=128, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38a8b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = [\n",
    "    [\"B-COMMA\" if \",\" in token_pred else \"O\" for token_pred in pred.split(\" \")]\n",
    "    for pred in preds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0480ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [\n",
    "    [\"B-COMMA\" if \",\" in token else \"O\" for token in text.split(\" \") if token == \"\" or clean_punctuation(token)]\n",
    "    for text in texts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d59d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.627561556791104,\n",
       "  'recall': 0.49219747702850025,\n",
       "  'f1': 0.5516976520904251,\n",
       "  'number': 32105},\n",
       " 'overall_precision': 0.627561556791104,\n",
       " 'overall_recall': 0.49219747702850025,\n",
       " 'overall_f1': 0.5516976520904251,\n",
       " 'overall_accuracy': 0.9527329349164484}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "873409e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.7959770114942529,\n",
       "  'recall': 0.6890547263681592,\n",
       "  'f1': 0.7386666666666667,\n",
       "  'number': 1206},\n",
       " 'overall_precision': 0.7959770114942529,\n",
       " 'overall_recall': 0.6890547263681592,\n",
       " 'overall_f1': 0.7386666666666667,\n",
       " 'overall_accuracy': 0.992344846441265}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tatoeba\n",
    "results = metric.compute(predictions=true_predictions[0:10000], references=true_labels[0:10000])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b590326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.6790646289817713,\n",
       "  'recall': 0.5947427834220287,\n",
       "  'f1': 0.6341127922971114,\n",
       "  'number': 6201},\n",
       " 'overall_precision': 0.6790646289817713,\n",
       " 'overall_recall': 0.5947427834220287,\n",
       " 'overall_f1': 0.6341127922971114,\n",
       " 'overall_accuracy': 0.9726602899705148}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oss\n",
    "results = metric.compute(predictions=true_predictions[10000:20000], references=true_labels[10000:20000])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3ddc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.6032076984763433,\n",
       "  'recall': 0.4568386104137987,\n",
       "  'f1': 0.5199179780199525,\n",
       "  'number': 24698},\n",
       " 'overall_precision': 0.6032076984763433,\n",
       " 'overall_recall': 0.4568386104137987,\n",
       " 'overall_f1': 0.5199179780199525,\n",
       " 'overall_accuracy': 0.9329644345070536}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gutenberg\n",
    "results = metric.compute(predictions=true_predictions[20000:30000], references=true_labels[20000:30000])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c02837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:09:22 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.7.2/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
      "[NeMo I 2022-04-23 21:09:22 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.7.2/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo\n",
      "[NeMo I 2022-04-23 21:09:22 common:704] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-04-23 21:09:26 tokenizer_utils:125] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpst0h_odi/tokenizer.vocab_file, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-23 21:09:31 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-04-23 21:09:31 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-04-23 21:09:31 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-04-23 21:09:31 modelPT:1243] World size can only be set by PyTorch Lightning Trainer.\n",
      "[NeMo W 2022-04-23 21:09:31 punctuation_capitalization_model:681] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-04-23 21:09:31 punctuation_capitalization_model:703] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n",
      "[NeMo W 2022-04-23 21:09:31 modelPT:215] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:09:36 save_restore_connector:157] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.7.2/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n"
     ]
    }
   ],
   "source": [
    "model_bert = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name=\"punctuation_en_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "696be5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-23 21:10:09 punctuation_capitalization_infer_dataset:91] Max length: 64\n",
      "[NeMo I 2022-04-23 21:10:09 data_preprocessing:358] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-23 21:10:09 data_preprocessing:360] Min: 0 |                  Max: 216 |                  Mean: 21.8305 |                  Median: 14.0\n",
      "[NeMo I 2022-04-23 21:10:09 data_preprocessing:366] 75 percentile: 27.00\n",
      "[NeMo I 2022-04-23 21:10:09 data_preprocessing:367] 99 percentile: 122.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 295/295 [06:16<00:00,  1.27s/batch]\n"
     ]
    }
   ],
   "source": [
    "preds = model_bert.add_punctuation_capitalization(texts_without_punctuation, batch_size=128, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6103481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = [\n",
    "    [\"B-COMMA\" if \",\" in token_pred else \"O\" for token_pred in pred.split(\" \")]\n",
    "    for pred in preds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86c1b10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.6923850126512079,\n",
       "  'recall': 0.6222083787572029,\n",
       "  'f1': 0.6554235842246866,\n",
       "  'number': 32105},\n",
       " 'overall_precision': 0.6923850126512079,\n",
       " 'overall_recall': 0.6222083787572029,\n",
       " 'overall_f1': 0.6554235842246866,\n",
       " 'overall_accuracy': 0.9613411691517108}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51965f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.8283712784588442,\n",
       "  'recall': 0.7844112769485904,\n",
       "  'f1': 0.8057921635434413,\n",
       "  'number': 1206},\n",
       " 'overall_precision': 0.8283712784588442,\n",
       " 'overall_recall': 0.7844112769485904,\n",
       " 'overall_f1': 0.8057921635434413,\n",
       " 'overall_accuracy': 0.9940633503013891}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tatoeba\n",
    "results = metric.compute(predictions=true_predictions[0:10000], references=true_labels[0:10000])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54bdbefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.7265179034769071,\n",
       "  'recall': 0.6773101112723754,\n",
       "  'f1': 0.7010515773660491,\n",
       "  'number': 6201},\n",
       " 'overall_precision': 0.7265179034769071,\n",
       " 'overall_recall': 0.6773101112723754,\n",
       " 'overall_f1': 0.7010515773660491,\n",
       " 'overall_accuracy': 0.9769899338990563}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oss\n",
    "results = metric.compute(predictions=true_predictions[10000:20000], references=true_labels[10000:20000])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a30af2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COMMA': {'precision': 0.6763042685151405,\n",
       "  'recall': 0.6004534780144142,\n",
       "  'f1': 0.6361257667395874,\n",
       "  'number': 24698},\n",
       " 'overall_precision': 0.6763042685151405,\n",
       " 'overall_recall': 0.6004534780144142,\n",
       " 'overall_f1': 0.6361257667395874,\n",
       " 'overall_accuracy': 0.9454179870349221}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gutenberg\n",
    "results = metric.compute(predictions=true_predictions[20000:30000], references=true_labels[20000:30000])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}